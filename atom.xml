<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Shallow Memory&#39;s Blog</title>
  
  <subtitle>生活明朗，万物可爱</subtitle>
  <link href="https://www.shallowrecall.top/atom.xml" rel="self"/>
  
  <link href="https://www.shallowrecall.top/"/>
  <updated>2024-02-08T10:35:26.328Z</updated>
  <id>https://www.shallowrecall.top/</id>
  
  <author>
    <name>Recall</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Hello World</title>
    <link href="https://www.shallowrecall.top/posts/4a17b156.html"/>
    <id>https://www.shallowrecall.top/posts/4a17b156.html</id>
    <published>2024-02-08T10:35:26.328Z</published>
    <updated>2024-02-08T10:35:26.328Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.io/docs/&quot;&gt;documentation&lt;/a&gt; for</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>数学基础编程题</title>
    <link href="https://www.shallowrecall.top/posts/c703b936.html"/>
    <id>https://www.shallowrecall.top/posts/c703b936.html</id>
    <published>2024-01-10T15:05:05.000Z</published>
    <updated>2024-02-08T10:35:26.328Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://images.shallowrecall.top/images/2024/1/img.png" alt="第一题"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">A = np.array([[<span class="number">2</span>, <span class="number">1</span>, <span class="number">4</span>, <span class="number">0</span>],</span><br><span class="line">              [<span class="number">1</span>, -<span class="number">1</span>, <span class="number">3</span>, <span class="number">4</span>]])</span><br><span class="line">B = np.array([[<span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>],</span><br><span class="line">              [<span class="number">0</span>, -<span class="number">1</span>, <span class="number">2</span>],</span><br><span class="line">              [<span class="number">1</span>, -<span class="number">3</span>, <span class="number">1</span>],</span><br><span class="line">              [<span class="number">4</span>, <span class="number">0</span>, -<span class="number">2</span>]])</span><br><span class="line">S = np.dot(A, B)</span><br><span class="line"><span class="built_in">print</span>(S)</span><br></pre></td></tr></table></figure><pre><code>[[ 6 -7  8] [20 -5 -6]]</code></pre><p>2、编程解决如下投入产出问题：某县区有A、B、C三个企业，A企业每生产l元的产品要消耗0.4元B企业的产品和0.3元C企业的产品；B企业每生产l元的产品要消耗0.7元A企业的产品、0.l2元自产的产品和0.2元C企业的产品；C企业每生产l元的产品要消耗0.6元A企业的产品和0.l5元B企业的产品。如果这3个企业接到的外来订单分别为7万元、8.5万元和5万元，那么他们各生产多少才能满足需求?模型假设：假设不考虑价格变动等其他因素。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义投入产出系数矩阵</span></span><br><span class="line">A = np.array([</span><br><span class="line">    [<span class="number">0</span>, <span class="number">0.7</span>, <span class="number">0.6</span>],  <span class="comment"># A企业自身不消耗，但生产1元产品需要消耗B企业0.7元，C企业0.6元的产品</span></span><br><span class="line">    [<span class="number">0.4</span>, <span class="number">0.12</span>, <span class="number">0</span>],  <span class="comment"># B企业生产1元产品需要消耗A企业0.4元，自身0.12元，C企业不消耗的产品</span></span><br><span class="line">    [<span class="number">0.3</span>, <span class="number">0.15</span>, <span class="number">0</span>]   <span class="comment"># C企业生产1元产品需要消耗A企业0.3元，B企业0.15元的产品</span></span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义外部订单需求向量</span></span><br><span class="line">d = np.array([<span class="number">70</span>, <span class="number">85</span>, <span class="number">50</span>])  <span class="comment"># 单位：万元</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算每个企业为了满足外部订单需求而必须生产的产品总额</span></span><br><span class="line"><span class="comment"># 系统方程为：x = Ax + d，可以重写为 (I - A)x = d，其中I为单位矩阵</span></span><br><span class="line">I = np.identity(<span class="number">3</span>)  <span class="comment"># 创建一个3x3的单位矩阵</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 解线性方程组 (I - A)x = d 来找到x</span></span><br><span class="line">x = np.linalg.solve(I - A, d)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打印每个企业需要生产的产品总额</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;A企业需要生产的产品总额（万元）:&quot;</span>, x[<span class="number">0</span>])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;B企业需要生产的产品总额（万元）:&quot;</span>, x[<span class="number">1</span>])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;C企业需要生产的产品总额（万元）:&quot;</span>, x[<span class="number">2</span>])</span><br></pre></td></tr></table></figure><pre><code>A企业需要生产的产品总额（万元）: 382.5197238658777B企业需要生产的产品总额（万元）: 270.46351084812625C企业需要生产的产品总额（万元）: 205.32544378698225</code></pre><p>3、编程解决如下问题：—个家禽养殖基地每天投入2元资金用于饲料、设备、人力，估计可使一只2千克重的鹅每天增加0.1千克。目前鹅出售市场价格为每千克30元，但是预测每天会降低0.04元。该基地应该什么时候出售这批鹅?如果上面的估计和预测有出入，那么对结果有多大影响?</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> scipy.optimize <span class="keyword">import</span> minimize_scalar</span><br><span class="line"></span><br><span class="line"><span class="comment"># 参数定义</span></span><br><span class="line">initial_weight = <span class="number">2</span>  <span class="comment"># 鹅的初始重量（千克）</span></span><br><span class="line">weight_gain_per_day = <span class="number">0.1</span>  <span class="comment"># 每天增重（千克）</span></span><br><span class="line">initial_price_per_kg = <span class="number">30</span>  <span class="comment"># 初始每千克价格（元）</span></span><br><span class="line">price_decrease_per_day = <span class="number">0.04</span>  <span class="comment"># 每天每千克价格下降（元）</span></span><br><span class="line">daily_investment = <span class="number">2</span>  <span class="comment"># 每天投资（元）</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义利润函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">profit</span>(<span class="params">days</span>):</span><br><span class="line">    total_weight = initial_weight + days * weight_gain_per_day</span><br><span class="line">    price_per_kg = initial_price_per_kg - days * price_decrease_per_day</span><br><span class="line">    total_revenue = total_weight * price_per_kg</span><br><span class="line">    total_cost = days * daily_investment</span><br><span class="line">    <span class="keyword">return</span> -(total_revenue - total_cost)  <span class="comment"># 我们用负值因为我们要最大化利润，而minimize_scalar是求最小值</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用数值优化方法找到最大化利润的天数</span></span><br><span class="line">result = minimize_scalar(profit, bounds=(<span class="number">0</span>, <span class="number">500</span>), method=<span class="string">&#x27;bounded&#x27;</span>)  <span class="comment"># 假设最多500天</span></span><br><span class="line"></span><br><span class="line">optimal_days = result.x</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;在第<span class="subst">&#123;<span class="built_in">round</span>(optimal_days)&#125;</span>天出售&quot;</span>)</span><br></pre></td></tr></table></figure><pre><code>在第115天出售</code></pre><p>4、用Python编程实现如何获得两组模拟的正态分布的数据并输出结果。正态分布模拟的标准差为δ＝0.l5和δ＝0.3的两组数据,共40个点,通过matplotlib模块绘制出曲线图。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> matplotlib.font_manager <span class="keyword">import</span> FontProperties</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置中文字体</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;SimHei&#x27;</span>]  <span class="comment"># 例如使用黑体</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span>  <span class="comment"># 解决负号“-”显示为方块的问题</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 正态分布的参数</span></span><br><span class="line">mean_1, mean_2 = <span class="number">0</span>, <span class="number">0</span>  <span class="comment"># 两组数据的均值</span></span><br><span class="line">std_dev_1, std_dev_2 = <span class="number">0.15</span>, <span class="number">0.3</span>  <span class="comment"># 两组数据的标准差</span></span><br><span class="line">n_points = <span class="number">40</span>  <span class="comment"># 每组数据的点数</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成两组正态分布的随机数据</span></span><br><span class="line">data_1 = np.random.normal(mean_1, std_dev_1, n_points)</span><br><span class="line">data_2 = np.random.normal(mean_2, std_dev_2, n_points)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对数据进行排序，以便绘图</span></span><br><span class="line">sorted_data_1 = np.sort(data_1)</span><br><span class="line">sorted_data_2 = np.sort(data_2)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 为data_1创建正态分布曲线</span></span><br><span class="line">fit_1 = <span class="number">1</span> / (std_dev_1 * np.sqrt(<span class="number">2</span> * np.pi)) * np.exp(-<span class="number">0.5</span> * ((sorted_data_1 - mean_1) / std_dev_1)**<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 为data_2创建正态分布曲线</span></span><br><span class="line">fit_2 = <span class="number">1</span> / (std_dev_2 * np.sqrt(<span class="number">2</span> * np.pi)) * np.exp(-<span class="number">0.5</span> * ((sorted_data_2 - mean_2) / std_dev_2)**<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制结果</span></span><br><span class="line">plt.plot(sorted_data_1, fit_1, label=<span class="string">f&#x27;正态分布（均值=<span class="subst">&#123;mean_1&#125;</span>, 标准差=<span class="subst">&#123;std_dev_1&#125;</span>）&#x27;</span>)</span><br><span class="line">plt.plot(sorted_data_2, fit_2, label=<span class="string">f&#x27;正态分布（均值=<span class="subst">&#123;mean_2&#125;</span>, 标准差=<span class="subst">&#123;std_dev_2&#125;</span>）&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.title(<span class="string">&#x27;不同标准差的正态分布&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;数值&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;概率密度&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://images.shallowrecall.top/images/2024/1/project_7_0.png" alt="png"><br>​</p><p>5、使用批量梯度下降算法拟合多维数据。待拟合的数据点为样本点对应的x值：[[6, 2], [8, 1], [10, 0], [14, 2], [18, 0]])，样本点对应的y值：[19, 21, 23, 43, 47])。上述数据点是根据函数y=3x1+4x2-7生成的。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 批量梯度下降算法</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">batch_gradient_descent</span>(<span class="params">X, y, learning_rate=<span class="number">0.001</span>, n_iterations=<span class="number">1000</span></span>):</span><br><span class="line">    m, n = X.shape</span><br><span class="line">    X_b = np.c_[np.ones((m, <span class="number">1</span>)), X]  <span class="comment"># 添加x0 = 1</span></span><br><span class="line">    theta = np.zeros((n + <span class="number">1</span>, <span class="number">1</span>))  <span class="comment"># 初始化参数为0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> iteration <span class="keyword">in</span> <span class="built_in">range</span>(n_iterations):</span><br><span class="line">        gradients = <span class="number">2</span>/m * X_b.T.dot(X_b.dot(theta) - y)</span><br><span class="line">        theta -= learning_rate * gradients</span><br><span class="line">    <span class="keyword">return</span> theta</span><br><span class="line"></span><br><span class="line"><span class="comment"># 样本点对应的x值和y值</span></span><br><span class="line">X = np.array([[<span class="number">6</span>, <span class="number">2</span>], [<span class="number">8</span>, <span class="number">1</span>], [<span class="number">10</span>, <span class="number">0</span>], [<span class="number">14</span>, <span class="number">2</span>], [<span class="number">18</span>, <span class="number">0</span>]])</span><br><span class="line">y = np.array([<span class="number">19</span>, <span class="number">21</span>, <span class="number">23</span>, <span class="number">43</span>, <span class="number">47</span>]).reshape(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 应用批量梯度下降算法</span></span><br><span class="line">theta = batch_gradient_descent(X, y)</span><br><span class="line"><span class="built_in">print</span>(theta)</span><br></pre></td></tr></table></figure><pre><code>[[-0.36773111] [ 2.59937037] [ 2.27070972]]</code></pre><p>6、某配送中心为所属的几个超市配送某品牌的厨具，假设超市每天对这种厨具的需求量是稳定的，订货费与每套产品每天的存贮费都是常数。如果超市对这种厨具的需求是可以缺货的，试编程制定最优的存贮策略。假设日需求为l00元，一次订货费为5000元，每套厨具每天的存贮费为l元，每套厨具每天的缺货费为0.l元。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">calculate_total_cost</span>(<span class="params">demand_per_day, ordering_cost, holding_cost_per_unit, shortage_cost_per_unit, order_quantity</span>):</span><br><span class="line">    days = order_quantity / demand_per_day</span><br><span class="line">    total_holding_cost = <span class="number">0.5</span> * order_quantity * holding_cost_per_unit * days</span><br><span class="line">    total_shortage_cost = <span class="number">0.5</span> * demand_per_day * shortage_cost_per_unit * days</span><br><span class="line">    total_ordering_cost = ordering_cost</span><br><span class="line">    <span class="keyword">return</span> total_ordering_cost + total_holding_cost + total_shortage_cost</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义参数</span></span><br><span class="line">demand_per_day = <span class="number">100</span>  <span class="comment"># 日需求</span></span><br><span class="line">ordering_cost = <span class="number">5000</span>  <span class="comment"># 一次订货费</span></span><br><span class="line">holding_cost_per_unit = <span class="number">1</span>  <span class="comment"># 每套厨具每天的存贮费</span></span><br><span class="line">shortage_cost_per_unit = <span class="number">0.1</span>  <span class="comment"># 每套厨具每天的缺货费</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算不同订货量下的总成本</span></span><br><span class="line">order_quantities = np.arange(demand_per_day, <span class="number">5000</span>, <span class="number">100</span>)  <span class="comment"># 从日需求量到一个较大的数值</span></span><br><span class="line">costs = [calculate_total_cost(demand_per_day, ordering_cost, holding_cost_per_unit, shortage_cost_per_unit, q) <span class="keyword">for</span> q <span class="keyword">in</span> order_quantities]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 找到成本最低的订货量</span></span><br><span class="line">optimal_order_quantity = order_quantities[np.argmin(costs)]</span><br><span class="line"><span class="built_in">print</span>(optimal_order_quantity)</span><br></pre></td></tr></table></figure><pre><code>100</code></pre><p><img src="https://images.shallowrecall.top/images/2024/1/img_1.png" alt="7"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义矩阵 A 和 B</span></span><br><span class="line">A = np.array([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">0</span>],</span><br><span class="line">              [<span class="number">2</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>],</span><br><span class="line">              [<span class="number">3</span>, -<span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>],</span><br><span class="line">              [<span class="number">1</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">3</span>]])</span><br><span class="line"></span><br><span class="line">B = np.array([[<span class="number">3</span>, <span class="number">4</span>, <span class="number">1</span>, -<span class="number">2</span>],</span><br><span class="line">              [<span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>],</span><br><span class="line">              [<span class="number">2</span>, -<span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>],</span><br><span class="line">              [<span class="number">1</span>, <span class="number">2</span>, -<span class="number">4</span>, <span class="number">3</span>]])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算 M = 4A^2 + 3AB - 2BA + 5B^2 + (AB)^T</span></span><br><span class="line">M = <span class="number">4</span> * np.dot(A, A) + <span class="number">3</span> * np.dot(A, B) - <span class="number">2</span> * np.dot(B, A) + <span class="number">5</span> * np.dot(B, B) + np.dot(A, B).T</span><br><span class="line"><span class="built_in">print</span>(M)</span><br></pre></td></tr></table></figure><pre><code>[[129  71 128  26] [ 93 113 -10  32] [ 84  51  28 -25] [155  85 -19 141]]</code></pre><p>8、编程解决如下金融公司支付基金的流动问题：金融机构为保证现金充分支付，设立—笔总额8600万元的基金，分开放置在位于甲城和乙城的两家公司，基金在平时可以使用，但每周末结算时必须确保总额仍然为8600万元。经过相当长的一段时期的现金流动，发现每过一周，各公司的支付基金在流通过程中多数还留在自己的公司内，而甲城公司有l5％支付基金流动到乙城公司，乙城公司则有l8％支付基金流动到甲城公司。起初甲城公司基金为4l00万元，乙城公司基金为4600万元。按此规律，两公司支付基金数额变化趋势如何?如果金融专家认为每个公司的支付基金不能少于3900万元，那么是否需要在必要时调动基金?</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 实现矩阵 M 的计算并打印结果</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义矩阵 A 和 B</span></span><br><span class="line">A = np.array([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">0</span>],</span><br><span class="line">              [<span class="number">2</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>],</span><br><span class="line">              [<span class="number">3</span>, -<span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>],</span><br><span class="line">              [<span class="number">1</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">3</span>]])</span><br><span class="line"></span><br><span class="line">B = np.array([[<span class="number">3</span>, <span class="number">4</span>, <span class="number">1</span>, -<span class="number">2</span>],</span><br><span class="line">              [<span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>],</span><br><span class="line">              [<span class="number">2</span>, -<span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>],</span><br><span class="line">              [<span class="number">1</span>, <span class="number">2</span>, -<span class="number">4</span>, <span class="number">3</span>]])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算 M = 4A^2 + 3AB - 2BA + 5B^2 + (AB)^T</span></span><br><span class="line">M = <span class="number">4</span> * np.dot(A, A) + <span class="number">3</span> * np.dot(A, B) - <span class="number">2</span> * np.dot(B, A) + <span class="number">5</span> * np.dot(B, B) + np.dot(A, B).T</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打印矩阵 M</span></span><br><span class="line"><span class="built_in">print</span>(M)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 金融公司支付基金的流动问题</span></span><br><span class="line"><span class="comment"># 定义状态转移矩阵</span></span><br><span class="line">transition_matrix = np.array([[<span class="number">0.85</span>, <span class="number">0.18</span>],</span><br><span class="line">                              [<span class="number">0.15</span>, <span class="number">0.82</span>]])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义初始基金分布</span></span><br><span class="line">funds_distribution = np.array([[<span class="number">4100</span>],</span><br><span class="line">                               [<span class="number">4500</span>]])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 进行多周的基金流动模拟</span></span><br><span class="line"><span class="keyword">for</span> week <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">53</span>):  <span class="comment"># 模拟一年的周数</span></span><br><span class="line">    funds_distribution = np.dot(transition_matrix, funds_distribution)</span><br><span class="line">    <span class="comment"># 检查是否需要调动基金</span></span><br><span class="line">    <span class="keyword">if</span> funds_distribution[<span class="number">0</span>] &lt; <span class="number">3900</span> <span class="keyword">or</span> funds_distribution[<span class="number">1</span>] &lt; <span class="number">3900</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;在第 <span class="subst">&#123;week&#125;</span> 周需要调动基金。&quot;</span>)</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 打印最终的基金分布</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;一年后甲城公司基金为：<span class="subst">&#123;funds_distribution[<span class="number">0</span>][<span class="number">0</span>]&#125;</span>万元&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;一年后乙城公司基金为：<span class="subst">&#123;funds_distribution[<span class="number">1</span>][<span class="number">0</span>]&#125;</span>万元&quot;</span>)</span><br></pre></td></tr></table></figure><pre><code>[[129  71 128  26] [ 93 113 -10  32] [ 84  51  28 -25] [155  85 -19 141]]一年后甲城公司基金为：4690.909090375244万元一年后乙城公司基金为：3909.090909624741万元</code></pre><p>9、编程计算全０、全１、单位二阶方阵的特征值与特征向量，并给出相应结果。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np  </span><br><span class="line"><span class="keyword">from</span> numpy.linalg <span class="keyword">import</span> eig  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 全0矩阵  </span></span><br><span class="line">A1 = np.zeros((<span class="number">2</span>,<span class="number">2</span>))  </span><br><span class="line"><span class="comment"># 全1矩阵  </span></span><br><span class="line">A2 = np.ones((<span class="number">2</span>,<span class="number">2</span>))  </span><br><span class="line"><span class="comment"># 单位矩阵  </span></span><br><span class="line">A3 = np.eye(<span class="number">2</span>)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 计算特征值和特征向量  </span></span><br><span class="line">eig_vals1, eig_vecs1 = eig(A1)  </span><br><span class="line">eig_vals2, eig_vecs2 = eig(A2)  </span><br><span class="line">eig_vals3, eig_vecs3 = eig(A3)  </span><br><span class="line">  </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;全0矩阵的特征值和特征向量:&quot;</span>)  </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;特征值:&quot;</span>, eig_vals1)  </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;特征向量:\n&quot;</span>, eig_vecs1)  </span><br><span class="line">  </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n全1矩阵的特征值和特征向量:&quot;</span>)  </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;特征值:&quot;</span>, eig_vals2)  </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;特征向量:\n&quot;</span>, eig_vecs2)  </span><br><span class="line">  </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n单位矩阵的特征值和特征向量:&quot;</span>)  </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;特征值:&quot;</span>, eig_vals3)  </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;特征向量:\n&quot;</span>, eig_vecs3)</span><br></pre></td></tr></table></figure><pre><code>全0矩阵的特征值和特征向量:特征值: [0. 0.]特征向量: [[1. 0.] [0. 1.]]全1矩阵的特征值和特征向量:特征值: [2. 0.]特征向量: [[ 0.70710678 -0.70710678] [ 0.70710678  0.70710678]]单位矩阵的特征值和特征向量:特征值: [1. 1.]特征向量: [[1. 0.] [0. 1.]]</code></pre><p>10、编程求向量的曼哈顿距离、欧氏距离和切比雪夫距离。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy.spatial <span class="keyword">import</span> distance</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义两个向量</span></span><br><span class="line">vector_a = np.array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line">vector_b = np.array([<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算曼哈顿距离</span></span><br><span class="line">manhattan_dist = distance.cityblock(vector_a, vector_b)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算欧氏距离</span></span><br><span class="line">euclidean_dist = distance.euclidean(vector_a, vector_b)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算切比雪夫距离</span></span><br><span class="line">chebyshev_dist = distance.chebyshev(vector_a, vector_b)</span><br><span class="line"></span><br><span class="line">manhattan_dist, euclidean_dist, chebyshev_dist</span><br></pre></td></tr></table></figure><pre><code>(9, 5.196152422706632, 3)</code></pre><p>11、用Python编程实现贝叶斯公式的计算：假设有两个教室各有l00个学生，A教室中有60个男生、40个女生，B教室中有30个男生、70个女生。假设随机选择其中一个教室,从里面叫出一个人记下性别再回到原来的教室，那么被选择的教室是A教室的概率有多大?</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义先验概率</span></span><br><span class="line">prob_A = <span class="number">1</span>/<span class="number">2</span>  <span class="comment"># 选择A教室的概率</span></span><br><span class="line">prob_B = <span class="number">1</span>/<span class="number">2</span>  <span class="comment"># 选择B教室的概率</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义条件概率</span></span><br><span class="line">prob_boy_given_A = <span class="number">60</span>/<span class="number">100</span>  <span class="comment"># A教室中选到男生的概率</span></span><br><span class="line">prob_boy_given_B = <span class="number">30</span>/<span class="number">100</span>  <span class="comment"># B教室中选到男生的概率</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 根据贝叶斯公式计算在已知选出的是男生的条件下，是从A教室选出的概率</span></span><br><span class="line"><span class="comment"># P(A|boy) = (P(boy|A) * P(A)) / (P(boy|A) * P(A) + P(boy|B) * P(B))</span></span><br><span class="line">prob_A_given_boy = (prob_boy_given_A * prob_A) / (prob_boy_given_A * prob_A + prob_boy_given_B * prob_B)</span><br><span class="line">prob_A_given_boy</span><br></pre></td></tr></table></figure><pre><code>0.6666666666666667</code></pre><p>12使用批量梯度下降算法拟合直线。待拟合的二维平面数据点：(6, 7)， (8, 9)， (10, 13)，(14, 17.5)， (18, 18)。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义批量梯度下降算法拟合直线</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">linear_regression</span>(<span class="params">X, y, learning_rate=<span class="number">0.001</span>, n_iterations=<span class="number">10000</span></span>):</span><br><span class="line">    m = <span class="built_in">len</span>(X)  <span class="comment"># 样本数量</span></span><br><span class="line">    X_b = np.c_[np.ones((m, <span class="number">1</span>)), X]  <span class="comment"># 添加x0 = 1</span></span><br><span class="line">    theta = np.random.randn(<span class="number">2</span>, <span class="number">1</span>)  <span class="comment"># 随机初始化参数</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> iteration <span class="keyword">in</span> <span class="built_in">range</span>(n_iterations):</span><br><span class="line">        gradients = <span class="number">2</span>/m * X_b.T.dot(X_b.dot(theta) - y)</span><br><span class="line">        theta -= learning_rate * gradients</span><br><span class="line">    <span class="keyword">return</span> theta</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义数据点</span></span><br><span class="line">X = np.array([<span class="number">6</span>, <span class="number">8</span>, <span class="number">10</span>, <span class="number">14</span>, <span class="number">18</span>]).reshape(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">y = np.array([<span class="number">7</span>, <span class="number">9</span>, <span class="number">13</span>, <span class="number">17.5</span>, <span class="number">18</span>]).reshape(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 应用线性回归模型</span></span><br><span class="line">theta = linear_regression(X, y)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(theta)</span><br></pre></td></tr></table></figure><pre><code>[[1.7207352 ] [0.99534866]]</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;img src=&quot;https://images.shallowrecall.top/images/2024/1/img.png&quot; alt=&quot;第一题&quot;&gt;&lt;/p&gt;
&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;g</summary>
      
    
    
    
    <category term="机器学习数学基础" scheme="https://www.shallowrecall.top/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80/"/>
    
    
  </entry>
  
  <entry>
    <title>计算机专业英语</title>
    <link href="https://www.shallowrecall.top/posts/62a3a0d6.html"/>
    <id>https://www.shallowrecall.top/posts/62a3a0d6.html</id>
    <published>2024-01-09T13:32:03.000Z</published>
    <updated>2024-02-08T10:35:26.328Z</updated>
    
    <content type="html"><![CDATA[<h1 id="计算机专业英语"><a href="#计算机专业英语" class="headerlink" title="计算机专业英语"></a>计算机专业英语</h1><ol><li><p>Waterfall model 瀑布模型</p><p><img src="https://images.shallowrecall.top/images/2024/1/wecom-temp-1001939-f3c97ec2812fe2e56245f3bc6310f0d9.png" alt="wecom-temp-1001939-f3c97ec2812fe2e56245f3bc6310f0d9"></p><p>Progress is seen as flowing steadily downwards through the phases of requirements analysis，design，implementation，testing，and maintenance.</p></li><li><p>Data Mining 数据挖掘</p><p>Several types of analytical software are available：statistics，machine learning，and neural networks.</p></li><li><p>Five types of relationships are sought：</p><ul><li>Classes analysis       分类分析</li><li>Cluster analysis          聚类分析</li><li>Association analysis  关联分析</li><li>Outlier analysis          孤立点分析</li><li>Sequential pattern analysis 序列模式分析</li></ul></li><li><p>段落翻译</p><ul><li>HarmonyOS 鸿蒙系统</li></ul><p>​        Huawei HarmonyOS is an operating system officially launched by Huawei at the Huawei Developer Conference(HDC) held in Dongguan on August 9,2019,as part of its broader push to solve China’s problem of lacking homegrown operating systems for fundamental digital technologies.</p><p>作为其更广泛努力解决中国缺乏基础数字技术本土操作系统问题的一部分。</p><p>​        HarmonyOS is a new distributed operating system oriented to the whole scence,creating a  super virual terminal interconnected world,connecting people ,equipment and scene organically,realizing rapid discovery,rapid connection,hardware mutual assistance and resource sharing of various intalligent terminals that consumers come into contact with in the whole scene of life.</p><p>HarmonyOS是面向全场景的新型分布式操作系统，打造了一个超级虚拟终端互联世界，将人、设备、场景有机地连接在一起，实现了消费者在生活全场景中接触到的各种智能终端的快速发现、快速连接、硬件互助和资源共享。</p><p>​        On September 10,2020,Huawei said that its in-house operating system HarmonyOS would be used in smartphones next year,marking a breakthrough in Chinese companies’ efforts to commercialize self-developed operating system and to build their own globally competive software ecosystems.The number of developers of HMS stood at over 1.8 million and the mobile applications integrated whit HMS so far have exceeded 96,000.</p><p>2020年9月10日，华为表示，其自有操作系统HarmonyOS将于明年用于智能手机，这标志着中国公司在将自主开发的操作系统商业化和构建自己的具有全球竞争力的软件生态系统方面取得了突破。HMS的开发者人数超过180万，到目前为止，与HMS集成的移动应用程序已经超过9.6万。</p><p>​        HarmonyOS is already used in Huawei’s smart TV products.With the upgrade of the system,and will be used in smartwatches,personal computers and other Internet of Things(IoT) devices later.</p><p>HarmonyOS已经在华为的智能电视产品中使用。随着系统的升级，并将在未来用于智能手表、个人电脑和其他物联网(IoT)设备。</p><p>​        Huawei has also promised to make HarmonyOS open source,which means anyone can freely examine the system specification to make sure there’s no problem.The code for small Internet of Things devices with 128 megabytes or less storage is available now.The code for larger device will be freely published in April 2021,and the remaining code will be available for download by October 2021.</p><p>华为还承诺将HarmonyOS开源，这意味着任何人都可以自由检查系统规范，以确保没有问题。128MB或更小存储空间的小型物联网设备的代码现已可用。较大设备的代码将于2021年4月免费发布，其余代码将于2021年10月供下载。</p><ul><li>Google</li></ul><p>​    Google is the most popular search engine with a stunning 91.42% market share.It holds first place in search with a difference of 88.28% from second in place Bing.According to statistics from Statista and StatCounter,Google is dominating the market in all countries on any device(desptop,mobile,and tablet).</p><p>谷歌是最受欢迎的搜索引擎，拥有惊人的91.42%的市场份额。谷歌以88.28%的差距位居搜索引擎首位，与第二位的必应相差88.28%。根据Statista和StatCounter的统计数据，谷歌在所有国家的任何设备(Deptop、移动设备和平板电脑)上都主导着市场。</p><p>​        What made Google the most popular and trusted search engine is the quality of its search results.Google is using sophisticated algorithms to present the most accurate results to the user.</p><p>谷歌之所以成为最受欢迎和最值得信赖的搜索引擎，是因为其搜索结果的质量。谷歌正在使用复杂的算法将最准确的结果呈现给用户。</p><p>​        Google’s founders Larry Page and Serey Brin came up with the idea that websites referenced by other websites are more important than others and thus deserv a higher ranking in the search results.</p><p>谷歌创始人拉里·佩奇和塞利·布林提出了一个想法，即被其他网站引用的网站比其他网站更重要，因此应该在搜索结果中获得更高的排名。</p><p>​        Over the years the Google ranking algorithm has been enriched with hundreds of other factors (including the help of machine learning) and still remains the most reliable way to find exactly what you are looking for on the Internet.</p><p>多年来，Google排名算法已经丰富了数百个其他因素（包括机器学习的帮助），并且仍然是在互联网上准确找到您正在寻找的内容的最可靠方法。</p><p>Router</p><p>​        Sometimes,however,the networks to be connected have incompatible characteristics.For instance ,the characteristics of a WIFI network are not readily compatible with an Ethernet network.In these cases the networks must be connected in a manner that builds a network of networks,known as an internet,in which the original networks their individuality and continue to function as autonomous networks .The connection between networks to form an internet is handled by devices known as routers,which are special purpose computers used for forwarding messages.</p><p>然而，有时要连接的网络具有不兼容的特性。例如，WiFi网络的特性不容易与以太网络兼容。在这些情况下，网络必须以一种建立网络网络的方式连接，称为因特网，在该网络中，原始网络具有其个性并继续作为自治网络起作用。网络之间的连接形成因特网由称为路由器的设备来处理，该设备是用于转发消息的专用计算机。</p></li><li><p>CPU</p><ul><li>the arithmetic / logic unit       算术逻辑单元</li><li>the control unit                        控制单元</li><li>the register unit                        寄存单元</li></ul></li><li><p>五层模型</p><ul><li>Application Layer</li><li>Transport Layer</li><li>Internet Layer</li><li>Link Layer</li><li>Physical Layer</li></ul><ol><li><p><strong>Application Layer:</strong> This topmost layer enables software applications to communicate over a network. It provides protocols that applications use to exchange data, like HTTP for web browsing and SMTP for email.</p><p>这一最顶层使软件应用程序能够通过网络进行通信。它提供了应用程序用来交换数据的协议，比如用于网页浏览的HTTP和用于电子邮件的SMTP。</p></li><li><p><strong>Transport Layer:</strong> This layer is responsible for the reliable transmission of data segments between points on a network, including error checking and data flow control. Protocols like TCP (Transmission Control Protocol) and UDP (User Datagram Protocol) operate at this layer.</p><p>这一层负责在网络上的点之间可靠地传输数据段，包括错误检查和数据流控制。像TCP(传输控制协议)和UDP(用户数据报协议)这样的协议在这一层运行。</p></li><li><p><strong>Internet Layer:</strong> This layer handles the routing of data packets across networks. The most famous protocol at this level is the Internet Protocol (IP), which is responsible for addressing and routing packets so they can travel between devices on different networks.</p><p>这一层处理数据包在网络上的路由。这一层最著名的协议是互联网协议（IP），它负责寻址和路由数据包，使它们可以在不同网络上的设备之间传输。</p></li><li><p><strong>Link Layer:</strong> Also known as the Data Link Layer, this layer is concerned with the network-specific transmission of data and handles the movement of packets between devices on the same network. This layer includes protocols like Ethernet and WiFi.</p><p>也称为数据链路层，该层负责特定于网络的数据传输，并处理同一网络中的设备之间的数据包移动。这一层包括以太网和WiFi等协议。</p></li><li><p><strong>Physical Layer:</strong> The foundational layer, it is responsible for the physical transmission of data over network communication media. It translates the digital data into electrical, radio, or optical signals. For example, this layer would determine how bits are modulated onto signals transmitted over Ethernet cables or through wireless connections.</p><p>基础层负责通过网络通信介质进行数据的物理传输。它将数字数据转换成电信号、无线电信号或光信号。例如，这一层将确定如何将位调制到通过以太网电缆或通过无线连接传输的信号上。</p></li></ol></li><li><p>云计算五大特征</p><ul><li>On-Demand Self-Service</li><li>Broad Network Access</li><li>Resource Pooling</li><li>Rapid Elasticity</li><li>Metered Service</li></ul><ol><li><p><strong>On-Demand Self-Service:</strong> Users can automatically provision computing resources like server time and network storage without requiring human interaction with service providers.</p><p>用户可以自动配置服务器时间和网络存储等计算资源，而无需与服务提供商进行人工交互。</p></li><li><p><strong>Broad Network Access:</strong> Resources are available over the network and can be accessed through standard mechanisms by diverse client platforms (e.g., mobile phones, laptops, and PDAs).</p><p>各种客户端平台(例如，移动电话、笔记本电脑和PDA)可以通过标准机制访问网络上的资源。</p></li><li><p><strong>Resource Pooling:</strong> The provider’s computing resources are pooled to serve multiple consumers, with different physical and virtual resources dynamically assigned and reassigned according to demand.</p><p>提供者的计算资源被集中起来为多个消费者服务，不同的物理和虚拟资源根据需求动态分配和重新分配。</p></li><li><p><strong>Rapid Elasticity:</strong> Capabilities can be elastically provisioned and released to scale rapidly outward and inward commensurate with demand, appearing to the user as unlimited resources that can be purchased in any quantity at any time.</p><p>可以灵活地配置和释放功能，以根据需求快速向外和向内扩展，在用户看来就像是可以在任何时间购买任何数量的无限资源。</p></li><li><p><strong>Metered Service:</strong> Cloud systems automatically control and optimize resource use by leveraging a metering capability at some level of abstraction appropriate to the type of service (e.g., storage, processing, bandwidth, and active user accounts). Users are billed based on service usage.</p><p>云系统通过在适合于服务类型的某个抽象级别（例如，存储、处理、带宽和活动用户帐户）。用户根据服务使用情况付费。</p></li></ol></li><li><p>SDLC（Softerware Development Life Cycle）软件生命周期</p></li></ol><ul><li>Analysis 需求分析</li><li>Design 设计</li><li>implementation 实施</li><li>Testing 测试</li><li>Development 部署</li><li>Maintenance 维护</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;计算机专业英语&quot;&gt;&lt;a href=&quot;#计算机专业英语&quot; class=&quot;headerlink&quot; title=&quot;计算机专业英语&quot;&gt;&lt;/a&gt;计算机专业英语&lt;/h1&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Waterfall model 瀑布模型&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;htt</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>数学基础考点</title>
    <link href="https://www.shallowrecall.top/posts/b1609aae.html"/>
    <id>https://www.shallowrecall.top/posts/b1609aae.html</id>
    <published>2024-01-07T03:43:17.000Z</published>
    <updated>2024-02-08T10:35:26.328Z</updated>
    
    <content type="html"><![CDATA[<ol><li><p>如何实现两个向量的数乘、内积、外积和分量乘法？</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义两个向量</span></span><br><span class="line">vector1 = np.array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line">vector2 = np.array([<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 数乘</span></span><br><span class="line">scalar_multiply = <span class="number">2</span>  <span class="comment"># 乘以2</span></span><br><span class="line">result_scalar_multiply = vector1 * scalar_multiply</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;数乘结果:&quot;</span>, result_scalar_multiply)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 内积（点积）</span></span><br><span class="line">dot_product = np.dot(vector1, vector2)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;内积结果:&quot;</span>, dot_product)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 外积（叉积）</span></span><br><span class="line">cross_product = np.cross(vector1, vector2)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;外积结果:&quot;</span>, cross_product)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 分量乘法</span></span><br><span class="line">component_multiply = vector1 * vector2</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;分量乘法结果:&quot;</span>, component_multiply)</span><br></pre></td></tr></table></figure></li><li><p>什么是哈达玛积(Hadamard product)？</p><p>哈达玛积（Hadamard<br>product）是一种针对两个相同维度的矩阵或向量进行元素级别的乘法运算。也就是说，它将两个矩阵或向量的对应元素相乘，生成一个新的矩阵或向量，新矩阵或向量的每个元素都是原始矩阵或向量中对应位置的元素相乘的结果。</p></li><li><p>对于p-范数,p分别取值0、1、2和∞时，分别对应着那几种范数，这些范数在numpy中如何编程实现？</p><ol><li>当p=0时，表示零范数（L0范数），它表示向量中非零元素的数量。</li><li>当p=1时，表示一范数（L1范数），它表示向量中所有元素的绝对值之和。</li><li>当p=2时，表示二范数（L2范数），它表示向量中所有元素的平方和的平方根，也叫做欧几里得范数。</li><li>当p=∞时，表示无穷范数（L∞范数），它表示向量中绝对值最大的元素。</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建一个示例向量</span></span><br><span class="line">v = np.array([<span class="number">1</span>, -<span class="number">2</span>, <span class="number">3</span>, -<span class="number">4</span>, <span class="number">5</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算不同p-范数</span></span><br><span class="line">p0_norm = np.linalg.norm(v, <span class="built_in">ord</span>=<span class="number">0</span>)  <span class="comment"># 零范数</span></span><br><span class="line">p1_norm = np.linalg.norm(v, <span class="built_in">ord</span>=<span class="number">1</span>)  <span class="comment"># 一范数</span></span><br><span class="line">p2_norm = np.linalg.norm(v, <span class="built_in">ord</span>=<span class="number">2</span>)  <span class="comment"># 二范数</span></span><br><span class="line">pinf_norm = np.linalg.norm(v, <span class="built_in">ord</span>=np.inf)  <span class="comment"># 无穷范数</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;L0范数:&quot;</span>, p0_norm)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;L1范数:&quot;</span>, p1_norm)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;L2范数:&quot;</span>, p2_norm)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;L∞范数:&quot;</span>, pinf_norm)</span><br></pre></td></tr></table></figure></li><li><p>如何编程计算全０、全１、单位二阶方阵的特征值与特征向量？</p><ol><li><p>计算全零矩阵的特征值和特征向量：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建全零矩阵</span></span><br><span class="line">zero_matrix = np.zeros((<span class="number">2</span>, <span class="number">2</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算特征值和特征向量</span></span><br><span class="line">eigenvalues, eigenvectors = np.linalg.eig(zero_matrix)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;全零矩阵的特征值：&quot;</span>, eigenvalues)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;全零矩阵的特征向量：\n&quot;</span>, eigenvectors)</span><br><span class="line"></span><br></pre></td></tr></table></figure></li><li><p>计算全一矩阵的特征值和特征向量：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建全一矩阵</span></span><br><span class="line">ones_matrix = np.ones((<span class="number">2</span>, <span class="number">2</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算特征值和特征向量</span></span><br><span class="line">eigenvalues, eigenvectors = np.linalg.eig(ones_matrix)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;全一矩阵的特征值：&quot;</span>, eigenvalues)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;全一矩阵的特征向量：\n&quot;</span>, eigenvectors)</span><br><span class="line"></span><br></pre></td></tr></table></figure></li><li><p>计算单位二阶方阵的特征值和特征向量：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建单位二阶方阵</span></span><br><span class="line">identity_matrix = np.identity(<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算特征值和特征向量</span></span><br><span class="line">eigenvalues, eigenvectors = np.linalg.eig(identity_matrix)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;单位二阶方阵的特征值：&quot;</span>, eigenvalues)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;单位二阶方阵的特征向量：\n&quot;</span>, eigenvectors)</span><br><span class="line"></span><br></pre></td></tr></table></figure></li></ol></li><li><p>什么是相似矩阵？相似矩阵具有什么性质？</p><p>相似矩阵是指存在相似关系的矩阵，即存在可逆矩阵P，使得P^(-1)AP=B</p><p>相似矩阵具有以下性质：</p><ol><li>特征值相同：如果两个矩阵A和B是相似矩阵，它们具有相同的特征值。这意味着它们在某种意义上描述了相同的线性变换。</li><li>特征向量关系：如果A和B是相似矩阵，并且v是A的一个特征向量，那么P^(-1) * v是B的相应特征向量。这说明相似矩阵之间的特征向量之间存在线性关系。</li><li>形式上的变换：相似矩阵关系B = P^(-1) <em> A </em> P可以看作是对矩阵A进行了一种相似变换，将A变换为B的形式。P是这个变换的转换矩阵。</li></ol></li><li><p>什么是矩阵的秩？什么是满秩矩阵？</p><p>​ 矩阵的秩是矩阵中非零行的最大数量，或者说是矩阵的行向量组中线性无关的最大数量。它表示了矩阵中包含的信息量和维度的重要性。具体来说，矩阵的秩是指能够通过线性组合（加法和数乘）生成矩阵中所有行的最小行数。</p><p>​ 满秩矩阵是指矩阵的秩等于其行数或列数中的较小值的矩阵。换句话说，对于一个n×m的矩阵，如果其秩等于n（行数）或m（列数）中的较小值，则该矩阵被称为满秩矩阵</p></li><li><p>矩阵的逆具有什么性质？如何编程计算矩阵的逆？</p><p>矩阵的逆是指对于一个可逆矩阵（也称为非奇异矩阵），存在一个矩阵，使得两者相乘得到单位矩阵。矩阵的逆具有以下性质：</p><ol><li>如果矩阵A有逆矩阵A^(-1)，则A^(-1)的逆也是A，即(A^(-1))^(-1) = A。</li><li>如果两个矩阵A和B都有逆矩阵，它们的乘积AB也有逆矩阵，且逆矩阵为(B^(-1)) * (A^(-1))。</li><li>单位矩阵I的逆矩阵是它自己，即I^(-1) = I。</li><li>零矩阵没有逆矩阵，因为没有矩阵可以与零矩阵相乘得到单位矩阵。</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建一个可逆矩阵</span></span><br><span class="line">matrix = np.array([[<span class="number">2</span>, <span class="number">1</span>], [<span class="number">1</span>, <span class="number">3</span>]])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算矩阵的逆</span></span><br><span class="line">inverse_matrix = np.linalg.inv(matrix)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;原始矩阵:\n&quot;</span>, matrix)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;矩阵的逆:\n&quot;</span>, inverse_matrix)</span><br></pre></td></tr></table></figure></li><li><p>什么是向量的线性相关、线性无关？</p><p>线性相关是指一组向量中至少有一个向量可以通过其他向量的线性组合来表示，存在依赖关系；线性无关是指一组向量中不存在非零的线性组合能够得到零向量，它们相互独立。</p></li><li><p>什么是特征向量，具有什么性质？</p><p>特征向量是矩阵的一个非零向量，当该向量与矩阵相乘时，仅仅发生伸缩而不改变方向。特征向量通常与特征值一起出现，它是表示线性变换中的固有方向的向量。</p><p>特征向量的性质包括：</p><ol><li><strong>定义</strong>：对于一个方阵A，如果存在一个非零向量v和一个标量λ（特征值），使得以下等式成立：A <em> v = λ </em><br>v，那么v就是A的特征向量，λ是对应的特征值。</li><li><strong>长度</strong>：特征向量的长度可以是任意的，但通常被标准化为单位向量，以便更容易理解其方向。</li><li><strong>复数性质</strong>：特征值可以是实数或复数，特征向量也可以对应复数特征值。</li><li><strong>多个特征向量</strong>：一个矩阵可以有多个特征向量和对应的特征值。</li><li><strong>表示变换方向</strong>：特征向量表示了矩阵的线性变换中的固有方向，它们保持在变换后的方向不变或仅发生伸缩。</li><li><strong>应用</strong>：特征向量和特征值在许多领域中有广泛的应用，包括线性代数、物理学、工程学、数据分析等。它们用于矩阵对角化、特征值分解、主成分分析（PCA）等任务。</li></ol></li><li><p>什么是正交矩阵？正交矩阵具有什么性质？</p><p>正交矩阵（Orthogonal Matrix）是一个方阵，其行向量和列向量都是标准正交的（单位长度且互相正交）。具体来说，正交矩阵满足以下两个条件：</p><ol><li>正交矩阵的行向量是单位向量，也就是每个行向量的长度（范数）等于1。</li><li>正交矩阵的列向量也是单位向量，并且互相正交，也就是每一对不同的列向量的内积为0。</li></ol><p>正交矩阵的性质包括：</p><ol><li>正交矩阵的转置是它的逆矩阵。如果矩阵Q是正交矩阵，则Q^T <em> Q = Q </em> Q^T = I，其中I是单位矩阵。</li><li>正交矩阵的行向量和列向量都构成标准正交基。这意味着它们可以用作向量空间的基，并且能够保持向量的长度和角度不变。</li><li>正交矩阵的行列式的绝对值等于1。即，det(Q) = ±1。</li><li>正交矩阵表示的线性变换保持向量的长度和角度不变，是一种保持欧几里得空间中距离和角度不变的变换。</li><li>正交矩阵在旋转、反射、镜像等几何变换中具有重要应用，因为它们保持了空间的正交性质。</li></ol></li><li><p>什么是LU分解、特征分解、奇异值分解？这三者有什么差异？</p><ol><li><strong>LU分解</strong>：<ul><li>LU分解是一种将一个矩阵分解为两个矩阵的方法，一个是下三角矩阵（Lower Triangular Matrix，L），另一个是上三角矩阵（Upper<br>Triangular Matrix，U）。</li><li>LU分解通常用于解线性方程组，可以将一个大型线性方程组的求解问题拆分成两个步骤，首先通过LU分解将系数矩阵分解为L和U，然后通过前代和回代的方式求解方程组。</li><li>LU分解不一定适用于所有矩阵，只适用于非奇异（可逆）矩阵。</li></ul></li><li><strong>特征分解</strong>：<ul><li>特征分解是一种将一个方阵分解为一组特征向量和对应的特征值的方法。</li><li>特征分解通常用于矩阵对角化，将一个矩阵表示为特征向量矩阵和特征值矩阵的乘积。</li><li>特征分解仅适用于某些类型的矩阵，例如对称矩阵。</li></ul></li><li><strong>奇异值分解</strong>：<ul><li>奇异值分解是一种将一个任意矩阵分解为三个矩阵的方法，一个是正交矩阵（通常是U矩阵），一个是对角矩阵（包含奇异值的Σ矩阵），另一个是正交矩阵的转置（通常是V^T矩阵）。</li><li>奇异值分解是一种广泛适用于任意矩阵的分解方法，没有像LU分解和特征分解那样的限制。</li><li>奇异值分解在降维、矩阵压缩、数据压缩、图像处理、机器学习等领域中有广泛应用。</li></ul></li></ol><p>差异：</p><ul><li>LU分解是用于解线性方程组的方法，将矩阵分解为下三角和上三角矩阵。</li><li>特征分解是将矩阵对角化的方法，将矩阵分解为特征向量和特征值的矩阵。</li><li>奇异值分解是将任意矩阵分解为三个矩阵的方法，通常用于降维和数据分析。</li></ul></li><li><p>什么是正定矩阵？正定矩阵具有什么性质？<br>正定矩阵（Positive Definite Matrix）是一类特殊的对称矩阵，具有一些重要的性质。一个n×n的实对称矩阵A被称为正定矩阵，如果对于任意非零实向量x，都满足以下条件：</p><p>x^T <em> A </em> x &gt; 0</p><p>其中，x^T表示x的转置，A表示矩阵A。这意味着正定矩阵的所有特征值都是正数，并且任何非零向量经过A的作用后，其结果都是正数。正定矩阵的性质包括：</p><ol><li>所有的特征值都是正数。即，A的特征值λ满足λ &gt; 0。</li><li>矩阵A的行列式（det(A)）是正数。</li><li>矩阵A的主子矩阵（由A的任意一些行和列组成的子矩阵）也是正定矩阵。</li><li>正定矩阵是对称的，即A等于其转置A^T。</li><li>正定矩阵是非奇异的（可逆的），因为它的行列式不为零。</li><li>正定矩阵在优化、数值计算和线性代数中具有重要应用，例如在正定线性规划、最小二乘法、协方差矩阵、多元统计分析等领域。</li></ol></li><li><p>用于相似性度量的二元函数应满足那些约束条件？<br>用于相似性度量的二元函数通常被称为相似性度量函数或相似性度量指标。这些函数用于衡量两个对象之间的相似性或相异性。这些函数应满足以下一些常见的约束条件和性质：</p><ol><li><strong>非负性（Non-Negativity）</strong>：相似性度量函数的值应始终为非负数，即对于所有的输入x和y，d(x, y) &gt;= 0。</li><li><strong>自反性（Reflexivity）</strong>：函数应满足自反性，即对于所有的输入x，d(x, x) = 0。这表示一个对象与自身的相似性应该最大。</li><li><strong>对称性（Symmetry）</strong>：函数应满足对称性，即对于所有的输入x和y，d(x, y) = d(y, x)。这表示两个对象之间的相似性度量不应依赖于它们的顺序。</li><li><strong>三角不等式（Triangle Inequality）</strong>：函数应满足三角不等式，即对于所有的输入x、y和z，d(x, y) + d(y, z) &gt;= d(x, z)<br>。这表示通过中介对象y测量的距离不应该小于直接测量的距离。</li><li><strong>有界性（Boundedness）</strong>：一些相似性度量函数可能需要满足有界性，即存在一个上界，使得函数的值不会无限增长。这可以帮助确保度量的稳定性</li></ol></li><li><p>闵可夫斯基距离包含那些类型，他们之间的关系如何？如何编程实现？</p><p><img src="https://images.shallowrecall.top/images/2024/1/image-20240107104243479.png" alt="image-20240107104243479"  /></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">minkowski_distance</span>(<span class="params">x, y, p=<span class="number">2</span></span>):</span><br><span class="line">    <span class="keyword">if</span> p == np.inf:</span><br><span class="line">        <span class="keyword">return</span> np.<span class="built_in">max</span>(np.<span class="built_in">abs</span>(x - y))</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> np.power(np.<span class="built_in">sum</span>(np.<span class="built_in">abs</span>(x - y) ** p), <span class="number">1</span>/p)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 示例用法</span></span><br><span class="line">point1 = np.array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line">point2 = np.array([<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>])</span><br><span class="line">p1_distance = minkowski_distance(point1, point2, p=<span class="number">1</span>)  <span class="comment"># 曼哈顿距离</span></span><br><span class="line">p2_distance = minkowski_distance(point1, point2, p=<span class="number">2</span>)  <span class="comment"># 欧几里德距离</span></span><br><span class="line">p_inf_distance = minkowski_distance(point1, point2, p=np.inf)  <span class="comment"># 切比雪夫距离</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;曼哈顿距离:&quot;</span>, p1_distance)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;欧几里德距离:&quot;</span>, p2_distance)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;切比雪夫距离:&quot;</span>, p_inf_distance)</span><br></pre></td></tr></table></figure></li><li><p>什么是马氏距离？它与欧氏距离有什么关系？</p><p><img src="https://images.shallowrecall.top/images/2024/1/image-20240107104452368.png" alt="image-20240107104452368"></p></li><li><p>什么是余弦距离和余弦相似度？</p><p><img src="https://images.shallowrecall.top/images/2024/1/image-20240107104840688.png" alt="image-20240107104840688"></p></li><li><p>什么是汉明距离？</p><p>汉明距离是指两个等长字符串之间的汉明距离，即两个字符串在相同位置上不同字符的个数。汉明距离以理查德·卫斯里·汉明的名字命名，是一种用于比较两个二进制数据字符串的度量。在信息论中，汉明距离也用于表示两个等长字符串之间的相似度，即需要替换多少个字符才能将一个字符串变成另一个字符串。</p><p>计算汉明距离的方法是，对两个字符串进行异或运算，并统计结果为1的个数。如果两个字符相同，则异或结果为0；如果两个字符不同，则异或结果为1。因此，对两个字符串进行异或运算，可以得出每个位置上不同字符的个数，即汉明距离。</p><p>汉明距离也可以用于比较两个等长二进制数据块的差异程度。在这种情况下，汉明距离可以用来检测数据传输中的错误。在数据传输过程中，如果由于噪音或干扰导致数据发生错误，那么接收端可以通过计算收到的数据与发送端的数据之间的汉明距离来检测错误。如果汉明距离较小，说明数据传输中错误较少；如果汉明距离较大，说明数据传输中错误较多。</p><p>此外，汉明重量是字符串相对于同样长度的零字符串的汉明距离，即非零的元素个数。对于二进制字符串来说，1的个数即为汉明重量。</p><p>总之，汉明距离是一种用于比较两个字符串或数据块差异程度的度量，常用于数据传输差错控制编码和信息论等领域。</p></li><li><p>什么是皮尔森距离？它与余弦距离是什么关系？</p><p><img src="https://images.shallowrecall.top/images/2024/1/image-20240107110044522.png" alt="image-20240107110044522"></p></li><li><p>什么是斯皮尔曼距离？什么是肯德尔距离？</p><p><img src="https://images.shallowrecall.top/images/2024/1/image-20240107110135794.png" alt="image-20240107110135794"></p></li><li><p>什么是凸集分离定理？</p><p><img src="https://images.shallowrecall.top/images/2024/1/image-20240107110236650.png" alt="image-20240107110236650"></p></li><li><p>函数的凹凸性与极值之间的关系是什么？</p><p><img src="https://images.shallowrecall.top/images/2024/1/image-20240107110329504.png" alt="image-20240107110329504"></p></li><li><p>什么是激活函数，其作用是什么？</p><p><img src="https://images.shallowrecall.top/images/2024/1/image-20240107110423525.png" alt="image-20240107110423525"></p></li><li><p>函数的连续与可导的关系是什么？函数可导的充要条件是什么?</p><p><img src="https://images.shallowrecall.top/images/2024/1/image-20240107110515862.png" alt="image-20240107110515862"></p></li><li><p>函数导数与凹凸性的关系如何？</p><p><img src="https://images.shallowrecall.top/images/2024/1/image-20240107110605183.png" alt="image-20240107110605183"></p></li><li><p>方向导数、梯度、散度的定义是什么？</p><p><img src="https://images.shallowrecall.top/images/2024/1/image-20240107110650782.png" alt="image-20240107110650782"></p></li><li><p>雅可比矩阵、Hessian矩阵的定义是什么？Hessan矩阵和Jacobi矩阵的关系如何？</p><p><img src="https://images.shallowrecall.top/images/2024/1/image-20240107110759474.png" alt="image-20240107110759474"></p></li><li><p>什么是全概率？什么是贝叶斯公式？</p><p><img src="https://images.shallowrecall.top/images/2024/1/image-20240107110841324.png" alt="image-20240107110841324"></p></li><li><p>如何编程实现两个数组的相关性？</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> pearsonr, spearmanr</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建两个示例数组</span></span><br><span class="line">array1 = np.array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>])</span><br><span class="line">array2 = np.array([<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算皮尔逊相关系数</span></span><br><span class="line">pearson_corr, _ = pearsonr(array1, array2)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;皮尔逊相关系数:&quot;</span>, pearson_corr)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算斯皮尔曼相关系数</span></span><br><span class="line">spearman_corr, _ = spearmanr(array1, array2)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;斯皮尔曼相关系数:&quot;</span>, spearman_corr)</span><br></pre></td></tr></table></figure></li><li><p>如何编程实现两个数组的协方差矩阵？协方差矩阵具有什么性质？</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建两个示例数组</span></span><br><span class="line">array1 = np.array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>])</span><br><span class="line">array2 = np.array([<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算协方差矩阵</span></span><br><span class="line">cov_matrix = np.cov(array1, array2)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;协方差矩阵:&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(cov_matrix)</span><br></pre></td></tr></table></figure><p><img src="https://images.shallowrecall.top/images/2024/1/image-20240107111018095.png" alt="image-20240107111018095"></p></li><li><p>如何编程画出正态分布曲线，分析不同参数对曲线的影响。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> norm</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义正态分布的均值和标准差</span></span><br><span class="line">mu_values = [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>]  <span class="comment"># 不同均值</span></span><br><span class="line">sigma_values = [<span class="number">0.5</span>, <span class="number">1</span>, <span class="number">1.5</span>]  <span class="comment"># 不同标准差</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建一个x轴的值范围</span></span><br><span class="line">x = np.linspace(-<span class="number">5</span>, <span class="number">5</span>, <span class="number">1000</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制不同参数下的正态分布曲线</span></span><br><span class="line">plt.figure(figsize=(<span class="number">12</span>, <span class="number">8</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> mu <span class="keyword">in</span> mu_values:</span><br><span class="line">    <span class="keyword">for</span> sigma <span class="keyword">in</span> sigma_values:</span><br><span class="line">        <span class="comment"># 计算概率密度函数（PDF）</span></span><br><span class="line">        pdf = norm.pdf(x, loc=mu, scale=sigma)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 绘制曲线</span></span><br><span class="line">        label = <span class="string">f&quot;μ=<span class="subst">&#123;mu&#125;</span>, σ=<span class="subst">&#123;sigma&#125;</span>&quot;</span></span><br><span class="line">        plt.plot(x, pdf, label=label)</span><br><span class="line"></span><br><span class="line">plt.title(<span class="string">&#x27;不同参数下的正态分布曲线&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;随机变量值&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;概率密度&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.grid(<span class="literal">True</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></li><li><p>什么是参数估计？参数估计量应那些基本特性？</p><p><img src="https://images.shallowrecall.top/images/2024/1/image-20240107111229225.png" alt="image-20240107111229225"></p></li><li><p>什么是无偏估计样本？样本统计量的典型代表有哪些？</p><p><img src="https://images.shallowrecall.top/images/2024/1/image-20240107111305015.png" alt="image-20240107111305015"></p></li><li><p>自编码器有哪些部件组成？分别具有那些功能？</p><p><img src="https://images.shallowrecall.top/images/2024/1/image-20240107111426129.png" alt="image-20240107111426129"></p></li><li><p>联合熵、条件熵、交叉熵和相对熵是如何定义的？</p><p><img src="https://images.shallowrecall.top/images/2024/1/image-20240107111511582.png" alt="image-20240107111511582"></p></li><li><p>卷积与池化的定义和功能是什么？</p><p><img src="https://images.shallowrecall.top/images/2024/1/image-20240107111557806.png" alt="image-20240107111557806"></p></li><li><p>什么是过拟合与欠拟合问题？如何避免过拟合与欠拟合？</p><p><img src="https://images.shallowrecall.top/images/2024/1/image-20240107111647208.png" alt="image-20240107111647208"></p></li><li><p>什么是奥卡姆剃刀原则？</p><p><img src="https://images.shallowrecall.top/images/2024/1/image-20240107111730503.png" alt="image-20240107111730503"></p></li><li><p>硬正则化和软正则化分别有那些方法？</p><p><img src="https://images.shallowrecall.top/images/2024/1/image-20240107111828990.png" alt="image-20240107111828990"></p></li><li><p>数据归一化、标准化的左右是什么？</p><p><img src="https://images.shallowrecall.top/images/2024/1/image-20240107111948379.png" alt="image-20240107111948379"></p><p>数据归一化和标准化的作用如下：</p><ol><li>数据归一化：将数据转换到特定的范围，如0-1之间，以便更好地进行数据处理和分析。归一化可以消除数据的规模和范围对分析的影响，使得不同量级的特征具有相同的尺度，从而避免某些特征在训练时占据主导地位。<br>2.<br>数据标准化：将数据按照一定的数学公式进行转换，使得数据的平均值为0，标准差为1，从而消除数据的量纲和单位对分析的影响。标准化可以使得不同量级的特征具有相同的尺度，避免某些特征在训练时占据主导地位。同时，标准化还可以使得数据更加符合正态分布，从而更好地进行机器学习模型的训练和预测。</li></ol></li><li><p>什么是期望风险、经验风险、置信风险和VC维？它们的相互关系如何？</p><p>期望风险、经验风险、置信风险和VC维都是机器学习和统计学中的概念，它们之间存在相互关联和差异。</p><ol><li>期望风险（Expected Risk）：是泛化风险的一种表示，它是在模型训练过程中预测错误的平均损失。期望风险的数学定义为：R(f) =<br>E[L(Y, f(X))] 其中，L(Y, f(X))表示损失函数，Y是真实值，f(X)是预测值，E表示期望。期望风险反映了模型对未知数据的预测能力。</li><li>经验风险（Empirical Risk）：又称为样本风险，是训练过程中样本损失的平均值。经验风险的数学定义为：R_emp(f) = 1/N Σ L(Y_i,<br>f(X_i)) 其中，N是样本数量，L(Y_i, f(X_i))表示第i个样本的损失，Σ表示求和。经验风险反映了模型对训练数据的拟合能力。</li><li>置信风险：是模型对未知数据的预测误差的估计误差。置信风险的数学定义为：R_conf(f) = E[R(f)] - R_emp(f) 其中，E[R(f)]<br>是期望风险的期望值。置信风险反映了模型预测的不确定性。</li><li>VC维（Vapnik-Chervonenkis Dimension）：是衡量模型复杂度和学习能力的指标。VC维的定义与具体模型有关，但一般来说，如果一个模型的VC维越高，则其表示能力越强，但过拟合的风险也越大。</li></ol><p>相互关系：</p><ul><li>期望风险、经验风险和置信风险都是衡量模型风险的指标，其中期望风险关注模型对未知数据的预测能力，经验风险关注模型对训练数据的拟合能力，置信风险关注模型预测的不确定性。</li><li>VC维是衡量模型复杂度和学习能力的指标，它与期望风险、经验风险和置信风险都有关系。一般来说，如果模型的VC维越高，则其表示能力越强，但过拟合的风险也越大，这可能会导致期望风险和经验风险的差异增大，从而增加置信风险。</li></ul><p>在实际应用中，需要根据具体问题和数据特性来选择合适的模型和算法，以平衡各种风险并获得最佳的预测效果。</p><p><img src="https://images.shallowrecall.top/images/2024/1/image-20240107112332136.png" alt="image-20240107112332136"></p><p>这些概念之间的关系可以总结如下：</p><ul><li>经验风险是在训练数据上测量的模型性能，期望风险是在整个数据分布上的期望性能，而置信风险是期望风险的一个上界估计，用于表示不确定性。</li><li>VC维反映了模型的复杂性，与模型的能力和泛化误差有关。较高的VC维可能导致较大的期望风险，特别是在样本量较小的情况下。</li></ul></li><li><p>函数最大化问题和函数最小化问题之间的关系？当前的最优化问题一般是哪一类问题？</p><p>​<br>函数最大化问题和函数最小化问题之间存在密切的关系，它们经常可以相互转化。具体来说，如果你有一个函数最大化的问题，你可以将其转化为一个函数最小化的问题，反之亦然。这是因为最大化问题的解通常可以通过将相应的函数取负值来转化为最小化问题，而最小化问题的解可以通过将相应的函数取相反数来转化为最大化问题。</p><p>​ 当前的最优化问题一般可以分为以下几类：</p><ol><li><strong>无约束最优化问题</strong>：在这类问题中，优化目标是最大化或最小化一个函数，没有约束条件。通常，这类问题可以通过计算函数的梯度或导数来寻找最优解。</li><li><strong>有约束最优化问题</strong>：这类问题中，除了优化目标函数外，还有一些约束条件，如等式约束和不等式约束。例如，线性规划问题就是一种有约束的最优化问题。</li><li><strong>整数最优化问题</strong>：在这类问题中，决策变量被限制为整数值。整数最优化问题常见于组合优化、离散优化和排程问题。</li><li><strong>凸优化问题</strong>：凸优化问题是一种特殊的最优化问题，其中优化目标函数和约束条件都是凸函数。凸优化问题具有良好的性质和可行解的存在保证，因此在实际中广泛应用。</li><li><strong>非凸优化问题</strong>：非凸优化问题中，优化目标函数和/或约束条件至少有一个是非凸函数。非凸问题通常更具挑战性，因为它们可能具有多个局部最优解。</li></ol></li><li><p>无约束优化与约束优化之间具有什么关系？</p><p><img src="https://images.shallowrecall.top/images/2024/1/image-20240107112631192.png" alt="image-20240107112631192"></p></li><li><p>什么是梯度下降法、牛顿法、拟牛顿法和坐标下降法？</p><ol><li><strong>梯度下降法（Gradient Descent）</strong>：<ul><li>梯度下降法是一种迭代优化算法，用于最小化目标函数。它的核心思想是通过迭代更新参数，使目标函数的值逐渐减小。</li><li>梯度下降法的步骤包括计算目标函数的梯度（导数），然后以负梯度方向作为搜索方向，更新参数。学习率是控制步长的超参数，影响算法的收敛速度和稳定性。</li><li>梯度下降法通常适用于大规模数据集和高维参数空间，但可能需要精心选择学习率。</li></ul></li><li><strong>牛顿法（Newton’s Method）</strong>：<ul><li>牛顿法是一种迭代优化算法，也用于最小化目标函数。它不仅使用目标函数的梯度，还利用了二阶导数信息（Hessian矩阵）。</li><li>牛顿法通过解牛顿方程来找到更新参数的方向，通常可以更快地收敛到局部最小值。但需要计算和存储Hessian矩阵，因此在高维参数空间中的应用有时不太实际。</li></ul></li><li><strong>拟牛顿法（Quasi-Newton Methods）</strong>：<ul><li>拟牛顿法是一类优化算法，旨在克服牛顿法中计算和存储Hessian矩阵的问题。它们通过估计Hessian矩阵的逆来近似牛顿法的步骤。</li><li>BFGS和L-BFGS（Limited-memory BFGS）是拟牛顿法的代表，它们在实际应用中往往比纯牛顿法更具吸引力，尤其是在高维参数空间中。</li></ul></li><li><strong>坐标下降法（Coordinate Descent）</strong>：<ul><li>坐标下降法是一种迭代优化算法，用于最小化目标函数，它将参数的更新分解为坐标方向的更新。</li><li>在每个迭代步骤中，坐标下降法选择一个坐标方向，将其固定，然后沿该方向最小化目标函数。这个过程在不同的坐标方向上交替进行。</li><li>坐标下降法通常用于高维优化问题，其中每次迭代只需要考虑一个坐标维度，因此计算成本较低。</li></ul></li></ol></li><li><p>相对梯度法，牛顿法、拟牛顿法具有那些改进？</p><ol><li><strong>相对梯度法</strong>：<ul><li>相对梯度法是一种基于相对梯度信息的优化算法，它不需要计算目标函数的梯度，而是使用相对梯度信息来更新参数。</li><li>优点：相对梯度法通常比传统的梯度法更鲁棒，特别适用于目标函数不可导或不易计算梯度的情况。它可以处理非光滑和非凸的目标函数。</li><li>缺点：相对梯度法可能需要更多的迭代步骤来达到收敛，因此在某些情况下可能比梯度法收敛较慢。</li></ul></li><li><strong>牛顿法</strong>：<ul><li>牛顿法是一种使用目标函数的梯度和二阶导数信息来进行迭代优化的算法。它通常能够更快地收敛到局部最小值。</li><li>优点：牛顿法通常具有更快的收敛速度，特别适用于光滑的凸优化问题。它能够更准确地估计最优解的位置。</li><li>缺点：牛顿法需要计算和存储目标函数的二阶导数（Hessian矩阵），这可能在高维问题中变得昂贵。此外，它对于非凸问题的收敛性不稳定。</li></ul></li><li><strong>拟牛顿法</strong>：<ul><li>拟牛顿法是一类优化算法，旨在克服牛顿法中计算和存储Hessian矩阵的问题。它们通过估计Hessian矩阵的逆来近似牛顿法的步骤。</li><li>优点：拟牛顿法在光滑的非线性优化问题中表现良好，并且不需要显式计算Hessian矩阵。它们通常在高维问题中表现较好。</li><li>缺点：尽管拟牛顿法在某些情况下能够提供较快的收敛速度，但它们不如牛顿法那样具有全局收敛性。此外，拟牛顿法的性能通常受到初始点的选择影响。</li></ul></li></ol><hr><p>相对梯度法，牛顿法和拟牛顿法具有以下改进：</p><ol><li>收敛速度：牛顿法和拟牛顿法通常具有比梯度下降法更快的收敛速度，因为它们利用了更高阶的信息来逼近函数的最小值点。这使得在处理大规模优化问题时，牛顿法和拟牛顿法能够更快地找到最优解。</li><li>所需梯度：梯度下降法需要计算目标函数的梯度，而牛顿法和拟牛顿法则需要计算目标函数的Hessian矩阵。在某些情况下，计算Hessian矩阵可能比计算梯度更加复杂，但牛顿法和拟牛顿法可以利用近似方法来简化这一计算过程。</li><li>局部最优解：梯度下降法容易陷入局部最优解，而牛顿法和拟牛顿法则通常能够更好地远离局部最优解，从而更有可能找到全局最优解。</li><li>参数调整：牛顿法和拟牛顿法通常需要调整的参数较少，因为它们利用了更高阶的信息，具有更好的数值稳定性和鲁棒性。</li></ol><p>综上所述，相对梯度法，牛顿法和拟牛顿法在收敛速度、所需梯度、局部最优解和参数调整等方面具有改进。在处理大规模优化问题时，这些方法通常能够更快地找到最优解，并且具有更好的数值稳定性和鲁棒性。</p></li><li><p>如果编程实现梯度下降法进行模型训练？</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成示例数据</span></span><br><span class="line">np.random.seed(<span class="number">0</span>)</span><br><span class="line">X = <span class="number">2</span> * np.random.rand(<span class="number">100</span>, <span class="number">1</span>)</span><br><span class="line">y = <span class="number">4</span> + <span class="number">3</span> * X + np.random.randn(<span class="number">100</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化模型参数</span></span><br><span class="line">theta = np.random.randn(<span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义学习率和迭代次数</span></span><br><span class="line">learning_rate = <span class="number">0.1</span></span><br><span class="line">num_iterations = <span class="number">1000</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 梯度下降训练模型</span></span><br><span class="line"><span class="keyword">for</span> iteration <span class="keyword">in</span> <span class="built_in">range</span>(num_iterations):</span><br><span class="line">    <span class="comment"># 计算梯度</span></span><br><span class="line">    gradients = -<span class="number">2</span>/<span class="built_in">len</span>(X) * X.T.dot(y - X.dot(theta))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 更新参数</span></span><br><span class="line">    theta = theta - learning_rate * gradients</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打印训练后的参数</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;训练后的参数 theta:&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(theta)</span><br><span class="line"></span><br></pre></td></tr></table></figure></li><li><p>如果编程实现批量梯度下降算法？</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成示例数据</span></span><br><span class="line">np.random.seed(<span class="number">0</span>)</span><br><span class="line">X = <span class="number">2</span> * np.random.rand(<span class="number">100</span>, <span class="number">1</span>)</span><br><span class="line">y = <span class="number">4</span> + <span class="number">3</span> * X + np.random.randn(<span class="number">100</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化模型参数</span></span><br><span class="line">theta = np.random.randn(<span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义学习率和迭代次数</span></span><br><span class="line">learning_rate = <span class="number">0.1</span></span><br><span class="line">num_iterations = <span class="number">1000</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 批量梯度下降训练模型</span></span><br><span class="line">m = <span class="built_in">len</span>(X)  <span class="comment"># 训练样本数量</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> iteration <span class="keyword">in</span> <span class="built_in">range</span>(num_iterations):</span><br><span class="line">    <span class="comment"># 计算梯度</span></span><br><span class="line">    gradients = -<span class="number">2</span>/m * X.T.dot(y - X.dot(theta))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 更新参数</span></span><br><span class="line">    theta = theta - learning_rate * gradients</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打印训练后的参数</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;训练后的参数 theta:&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(theta)</span><br></pre></td></tr></table></figure></li><li><p>查准率和查全率是如何定义的？它们的关系是怎样的？</p><p><img src="https://images.shallowrecall.top/images/2024/1/image-20240107113500900.png" alt="image-20240107113500900"></p></li><li><p>什么是P-R曲线？如何根据P-R曲线判断模型性能优劣？</p><p><img src="https://images.shallowrecall.top/images/2024/1/image-20240107113549809.png" alt="image-20240107113549809"></p></li><li><p>什么是ROC曲线？如何根据ROC曲线判断模型性能优劣？</p><p><img src="https://images.shallowrecall.top/images/2024/1/image-20240107113622263.png" alt="image-20240107113622263"></p></li><li><p>什么是混淆矩阵？混淆矩阵主要由哪些元素构成？</p><p>混淆矩阵（Confusion Matrix），也称为误差矩阵（Error Matrix）或分类表（Contingency Table），是用于评估二分类模型性能的重要工具。它主要由以下四个元素构成：</p><ol><li><p><strong>真正例（True Positives，TP）</strong>：表示模型正确预测为正类别的样本数量。这是实际正类别样本被正确分类的数量。</p></li><li><p><strong>假正例（False Positives，FP）</strong>：表示模型错误预测为正类别的样本数量。这是实际负类别样本被错误分类为正类别的数量。</p></li><li><p><strong>真负例（True Negatives，TN）</strong>：表示模型正确预测为负类别的样本数量。这是实际负类别样本被正确分类的数量。</p></li><li><p><strong>假负例（False Negatives，FN）</strong>：表示模型错误预测为负类别的样本数量。这是实际正类别样本被错误分类为负类别的数量。</p></li></ol><p>混淆矩阵通常以如下形式呈现：</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">         |   实际正类别    |    实际负类别</span></span><br><span class="line"><span class="section">----------------------------------------</span></span><br><span class="line"><span class="section">预测为正 |   TP            |    FP</span></span><br><span class="line"><span class="section">----------------------------------------</span></span><br><span class="line">预测为负 |   FN            |    TN</span><br></pre></td></tr></table></figure><p>混淆矩阵的四个元素可以用于计算各种性能指标，包括查准率（Precision）、查全率（Recall）、F1分数（F1-Score）、准确率（Accuracy）、假正例率（False<br>Positive Rate，FPR）等，这些指标有助于全面评估模型的性能。</p><p>混淆矩阵是评估二分类模型性能的关键组成部分，它提供了详细的信息，帮助我们理解模型在不同类别上的表现，特别是在类别不平衡的情况下。通过分析混淆矩阵，可以确定模型的优势和劣势，优化模型的性能，以及根据任务需求进行适当的调整。</p></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;ol&gt;
&lt;li&gt;&lt;p&gt;如何实现两个向量的数乘、内积、外积和分量乘法？&lt;/p&gt;
&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;</summary>
      
    
    
    
    <category term="机器学习数学基础" scheme="https://www.shallowrecall.top/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80/"/>
    
    
  </entry>
  
  <entry>
    <title>响应状态码</title>
    <link href="https://www.shallowrecall.top/posts/505b9ee7.html"/>
    <id>https://www.shallowrecall.top/posts/505b9ee7.html</id>
    <published>2023-12-17T04:54:28.000Z</published>
    <updated>2024-02-08T11:49:00.011Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、状态码大类"><a href="#一、状态码大类" class="headerlink" title="一、状态码大类"></a>一、状态码大类</h2><div class="table-container"><table><thead><tr><th>状态码分类</th><th>说明</th></tr></thead><tbody><tr><td>1xx</td><td><strong>响应中</strong>——临时状态码，表示请求已经接受，告诉客户端应该继续请求或者如果它已经完成则忽略它</td></tr><tr><td>2xx</td><td><strong>成功</strong>——表示请求已经被成功接收，处理已完成</td></tr><tr><td>3xx</td><td><strong>重定向</strong>——重定向到其它地方：它让客户端再发起一个请求以完成整个处理。</td></tr><tr><td>4xx</td><td><strong>客户端错误</strong>——处理发生错误，责任在客户端，如：客户端的请求一个不存在的资源，客户端未被授权，禁止访问等</td></tr><tr><td>5xx</td><td><strong>服务器端错误</strong>——处理发生错误，责任在服务端，如：服务端抛出异常，路由出错，HTTP版本不支持等</td></tr></tbody></table></div><h2 id="二、常见的响应状态码"><a href="#二、常见的响应状态码" class="headerlink" title="二、常见的响应状态码"></a>二、常见的响应状态码</h2><div class="table-container"><table><thead><tr><th>状态码</th><th>英文描述</th><th>解释</th></tr></thead><tbody><tr><td>==200==</td><td><strong><code>OK</code></strong></td><td>客户端请求成功，即<strong>处理成功</strong>，这是我们最想看到的状态码</td></tr><tr><td>302</td><td><strong><code>Found</code></strong></td><td>指示所请求的资源已移动到由<code>Location</code>响应头给定的 URL，浏览器会自动重新访问到这个页面</td></tr><tr><td>304</td><td><strong><code>Not Modified</code></strong></td><td>告诉客户端，你请求的资源至上次取得后，服务端并未更改，你直接用你本地缓存吧。隐式重定向</td></tr><tr><td>400</td><td><strong><code>Bad Request</code></strong></td><td>客户端请求有<strong>语法错误</strong>，不能被服务器所理解</td></tr><tr><td>403</td><td><strong><code>Forbidden</code></strong></td><td>服务器收到请求，但是<strong>拒绝提供服务</strong>，比如：没有权限访问相关资源</td></tr><tr><td>==404==</td><td><strong><code>Not Found</code></strong></td><td><strong>请求资源不存在</strong>，一般是URL输入有误，或者网站资源被删除了</td></tr><tr><td>405</td><td><strong><code>Method Not Allowed</code></strong></td><td>请求方式有误，比如应该用GET请求方式的资源，用了POST</td></tr><tr><td>428</td><td><strong><code>Precondition Required</code></strong></td><td><strong>服务器要求有条件的请求</strong>，告诉客户端要想访问该资源，必须携带特定的请求头</td></tr><tr><td>429</td><td><strong><code>Too Many Requests</code></strong></td><td>指示用户在给定时间内发送了<strong>太多请求</strong>（“限速”），配合 Retry-After(多长时间后可以请求)响应头一起使用</td></tr><tr><td>431</td><td><strong><code>Request Header Fields Too Large</code></strong></td><td><strong>请求头太大</strong>，服务器不愿意处理请求，因为它的头部字段太大。请求可以在减少请求头域的大小后重新提交。</td></tr><tr><td>==500==</td><td><strong><code>Internal Server Error</code></strong></td><td><strong>服务器发生不可预期的错误</strong>。服务器出异常了，赶紧看日志去吧</td></tr><tr><td>503</td><td><strong><code>Service Unavailable</code></strong></td><td><strong>服务器尚未准备好处理请求</strong>，服务器刚刚启动，还未初始化好</td></tr></tbody></table></div><p>状态码大全：<a href="https://cloud.tencent.com/developer/chapter/13553">https://cloud.tencent.com/developer/chapter/13553</a> </p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;一、状态码大类&quot;&gt;&lt;a href=&quot;#一、状态码大类&quot; class=&quot;headerlink&quot; title=&quot;一、状态码大类&quot;&gt;&lt;/a&gt;一、状态码大类&lt;/h2&gt;&lt;div class=&quot;table-container&quot;&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;t</summary>
      
    
    
    
    <category term="HTTP协议" scheme="https://www.shallowrecall.top/categories/HTTP%E5%8D%8F%E8%AE%AE/"/>
    
    
    <category term="技术" scheme="https://www.shallowrecall.top/tags/%E6%8A%80%E6%9C%AF/"/>
    
  </entry>
  
  <entry>
    <title>词汇</title>
    <link href="https://www.shallowrecall.top/posts/85fc7b85.html"/>
    <id>https://www.shallowrecall.top/posts/85fc7b85.html</id>
    <published>2023-11-01T03:26:54.000Z</published>
    <updated>2024-02-08T10:35:26.329Z</updated>
    
    <content type="html"><![CDATA[<h3 id="2023-11-1"><a href="#2023-11-1" class="headerlink" title="2023-11-1"></a>2023-11-1</h3><h4 id="词汇"><a href="#词汇" class="headerlink" title="词汇"></a>词汇</h4><ol><li>comment     n. 评论  v. 表达意见 </li><li>private              adj. 私人的，个人的     ==  personal</li><li>take out            v. 取出，除去; 拔掉; 把…带出去; 邀请（某人）外出</li><li>context              n. 上下文，情景，语境</li><li>ruin                    v. 毁掉，摧毁</li><li>candidate          n. 候选人; 应试者; 申请人; 被认定适合者</li><li>hired                   v. 聘用( hire的过去式和过去分词 ); 录用; 雇用; 租用</li><li>conversely          adv. 相反的</li><li>opt                       v. 选择 (for)</li><li>fit                          v. 适合</li><li><p>align                     v. 和……相符(with)，匹配  vt. 使成一线，使结盟; 排整齐 vi. 排列; 成一条线</p></li><li><p>sense                   n. 感觉，官能; 意识，观念; 理性; 识别力 vt. 感到; 理解，领会; 检测出</p></li><li>confidence          n. 信心; 信任; 秘密  adj. 骗得信任的; 欺诈的</li><li>proposal              n. 提议; 建议; 求婚; 〈美〉投标</li><li>propose               v. 提议，建议; 打算，计划; 推荐，提名; 求婚 vi. 做出计划，打算; 求婚</li><li>strengthen          vt. 加强，巩固; 勉励，激励; 增加…的艺术效果; （价格）上涨 vi. 变强; 变坚挺</li></ol><blockquote><p>“en” 是一个英文中的后缀，通常用于动词上，用以表示使动用法。当在动词后加上 “-en” 后缀时，通常会改变动词的词性或者增强其含义。这种形式在一些动词中使用较为常见，例如：</p><ol><li>Soften（软化）：make or become soft（使变软或变得柔软）。</li><li>Brighten（变亮）：make or become brighter（使变亮或变得明亮）。</li><li>Flatten（变平）：make or become flat（使变平或变得平坦）。</li><li>Darken（变暗）：make or become dark（使变暗或变得昏暗）。</li></ol><p>这些是一些常见的以 “-en” 结尾的动词示例，但并非所有以此后缀结尾的动词都遵循相同的规则，因此在学习和使用中应注意具体的词义和用法。</p></blockquote><ol><li>digital                  adj. 数字的; 数据的; 手指的; 指状的 n. 手指; （钢琴等的）琴键; 数字</li><li>inheritance        n. 继承; 遗传; 遗产</li><li>heritage               n. 遗产; 继承物; 传统; 文化遗产 </li><li>archaeologists    n. 考古学家</li><li>seek                      vt. 寻找，探寻; 追求，谋求; 往或朝…而去; [废语]考察 vi. 查找，查寻; 找一找</li><li>rise                        vi. 上升；攀升；提高；达到较高水平（或位置）；起床；起立；站起来；升起 n. （数量或水平的）增加，提高；加薪；工资增长；(重要性、优势、权力等的)增强</li><li>go to great length to do sth            竭尽全力做某</li><li>reputation                                          n.名声，名誉</li><li>the + adj                                              表示一类人 eg : the poor 穷人、the rich 富人</li><li>give sb sth/give sth to sb                  给某人某物</li><li>promotion                                           n.促进，增进; 提升，升级; （商品等的）推广; 发扬</li><li>limited-edition                                    adj. 限量版的</li><li>blind-box                                             n. 盲盒</li><li>family bucket                                      全家桶</li><li>induce                                                  vt. 引诱; 引起; [电]感应; 归纳</li><li>impulse purchase                               冲动消费，冲动购物</li><li>consumer                                             n. 消费者，顾客</li><li>cause                                                     n. 原因; 动机; 理由; 事业  vt. 成为…的原因; 导致; 引起; 使遭受</li><li>deal                                                       vt. [牌戏]分; 分配; 经营; 施予 n. （一笔）交易; 许多; 待遇; 发牌 vi. 论述; （有效地或成功地）处理; 惩处; 交易 adj. 冷杉木制的，松木制的</li><li>be expected to do sth                        有望做某事，应该做某事</li><li>value                                                      n. 价值，价格; 意义，涵义; 重要性; （邮票的）面值  vt. 评价; 重视，看重; 估价，给…定价</li><li>million                                                    n. 百万 adj. 百万的;无数的</li><li>equivalent                                              adj. 相等的，相当的，等效的; 等价的，等积的; [化学]当量的 n. 对等物; [化学]当量</li><li>equivalent to                                          相当于，折合</li><li>arund                                                       adv. 大约; 旋转; 到处，四处; 在周围 prep. 围绕; 在附近; 前后，左右; 在…周围</li><li>announce                                              vi. 宣布参加竞选; 当播音员 vt. 宣布; 述说; 声称; 预告</li><li>admire                                                   vt. 赞赏; 称赞; 欣赏; &lt;美口&gt;想要</li><li>discourage                                            vt. 使气馁; 使沮丧; 阻碍; 劝阻</li><li>spirit                                                       n. 精神，心灵; 情绪; 勇气; 精髓 v. 神秘地带走</li><li>team spirit                                             n. 合作精神，团队精神</li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;2023-11-1&quot;&gt;&lt;a href=&quot;#2023-11-1&quot; class=&quot;headerlink&quot; title=&quot;2023-11-1&quot;&gt;&lt;/a&gt;2023-11-1&lt;/h3&gt;&lt;h4 id=&quot;词汇&quot;&gt;&lt;a href=&quot;#词汇&quot; class=&quot;headerlink&quot; </summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>四级笔记</title>
    <link href="https://www.shallowrecall.top/posts/2353f099.html"/>
    <id>https://www.shallowrecall.top/posts/2353f099.html</id>
    <published>2023-10-31T23:08:53.000Z</published>
    <updated>2024-02-08T10:35:26.328Z</updated>
    
    <content type="html"><![CDATA[<h2 id="语法"><a href="#语法" class="headerlink" title="语法"></a>语法</h2><h3 id="一、秒懂长难句"><a href="#一、秒懂长难句" class="headerlink" title="一、秒懂长难句"></a>一、秒懂长难句</h3><blockquote><p>做减法</p></blockquote><p>减些啥？</p><ol><li>插入语     <strong>[两个破折号之间；两个逗号之间(修饰关系)]</strong></li><li>作修饰成分的介词短语/to do/doing/done</li><li>从句(连接词始，一般第二个动词止)</li></ol><blockquote><p>例句：</p></blockquote><h4 id="例句一"><a href="#例句一" class="headerlink" title="例句一"></a>例句一</h4><ol><li>Pictures or comments on a private page that are taken out of context could ruin a perfectly good candidate’s chances of getting hired.</li></ol><p>Pictures or comments <del>on a private page that are taken out of context</del> could ruin <del>a perfectly good candidate’s</del> chances <del>of getting hired</del>.</p><hr><p>on a private page、of getting hired    介短</p><p>that are taken of context                从句</p><p>a perfectly good candidate’s                  修饰成分</p><hr><p>Pictures or comments could ruin chances.</p><p>图片或评论可能会毁掉机会。</p><p>Pictures or comments (on a private page) could ruin chances.</p><p><u>个人页面上的</u>图片或评论可能会毁掉机会。</p><p>Pictures or comments on a private page (that are taken out of context) could ruin chances.</p><p>脱离了语境   ==&gt;  断章取义</p><p>个人页面上<u>断章取义</u>的图片或评论可能会毁掉机会</p><p>Pictures or comments on a private page that are taken out of context could ruin chances (of getting hired).</p><p><u>个人页面上</u><u>断章取义的</u>图片或评论可能会毁掉<u>被雇佣的</u>机会。</p><p>Pictures or comments on a private page that are taken out of context could ruin (a perfectly good candidate’s) chances of getting hired.</p><p><u>个人页面上</u><u>断章取义的</u> <strong>图片或评论可能会毁掉</strong> <u>一个非常好的候选人</u> <u>被雇佣的</u> <strong>机会</strong>。</p><h4 id="例句二"><a href="#例句二" class="headerlink" title="例句二"></a>例句二</h4><ol><li>Conversely,she says, opting for clothrs that fit well and align with your sense of style can improve your confidence.</li></ol><p><del>Conversely</del>,<del>she says</del>, opting for clothrs <del>that fit well and align with your sense of style</del> can improve your confidence.</p><hr><p>Conversely    副词，修饰整个句子，修饰成分</p><p>for clothrs     因为 opting for 固定搭配，所以可以不删</p><p>she says    两个逗号之间，且是修饰成分</p><p>that fit well and align with your sense of style    从句，一般到第二个动词，但是这个是并列关系，例外</p><hr><p>opting for clothrs can improve your confidence.</p><p>选择衣服可以增加你的自信。</p><p>opting for clothrs (that fit well and align with your sense of style) can improve your confidence.</p><p>选择<u>合身且符合你风格的</u>衣服可以增加你的</p><p>Conversely,she says,opting for clothrs that fit well and align with your sense of style can improve your confidence.</p><p><u>相反的是，她说，</u> 选择 <u>合身且符合你风格的</u> 衣服可以增加你的自信。</p><h4 id="练习一"><a href="#练习一" class="headerlink" title="练习一"></a>练习一</h4><ol><li>A proposal to strengthen digital protection and inheritance of cultural heritage earned wide support among Chinese cultural experts and archaeologists on Wednesday.</li></ol><p>A proposal <del>to strengthen digital protection and inheritance</del> <del>of cultural heritage</del> earned wide support <del>among Chinese cultural experts and archaeologists</del> <del>on Wednesday.</del></p><hr><p>to strengthen digital protection and inheritance  不定式短语</p><p>of cultural heritage 介短</p><p>among Chinese cultural experts and archaeologists 状语</p><p> on Wednesday. 时间状语</p><hr><p>A proposal earned wide support.</p><p>一项提案赢得了广泛的支持。</p><p>to strengthen digital protection and inheritance</p><p>加强数字化的保护和传承(修饰一)</p><p>of cultural heritage</p><p>文化遗产的(修饰二)</p><p>among Chinese cultural experts and archaeologists</p><p>在中国文化专家和考古学家之间(修饰三)</p><p>On Wednesday    在周三</p><p>1）周三，一项加强文化遗产数字保护和传承的提案赢得了中国文化专家和考古学家的广泛支持。</p><p>2）周三，一项提案赢得了中国文化专家和考古学家的广泛支持，这项提案旨在加强文化遗产数字保护和传承。</p><h4 id="练习二"><a href="#练习二" class="headerlink" title="练习二"></a>练习二</h4><ol><li>The number of girls who seek to hide their probleams from others has also risen,with 60% of girls going to great lengths to hide feelings of unhappiness compared with 80% now.</li></ol><p>The number <del>of girls   ~who seek to hide their probleams from others</del> has also risen,<del>with 60% of girls going to great lengths to hide feelings</del> <del>of unhappiness compared with 80% now</del>.</p><hr><p>of girls</p><p>with 60% of girls going to great lengths to hide feelings of unhappiness </p><p>compared with 80% now.</p><p>who seek to hide their probleams from others</p><hr><p>The number has also risen.    数量也增加了。</p><p>The number (of girls) has also risen.    女孩的数量也增加了。</p><p>The number of girls (who seek to hide their probiems from others) has also risen.    试图向他人隐藏自己问题的女孩的数量也增加了。</p><p>The number of girls who seek to hide their probiems from others has also risen,(with 60% of girls going to great lengths to hide feelings of unhappiness )</p><p>试图向他人隐藏自己问题的女孩的数量也增加了，<u>60%的女孩会竭尽全力隐藏自己的不快。</u></p><p>The number of girls who seek to hide their probiems from others has also risen,with 60% of girls going to great lengths to hide feelings of unhappiness </p><p>(compared with 80% now.)    </p><p>试图向他人隐藏自己问题的女孩的数量也增加了，60%的女孩会竭尽全力隐藏自己的不快,<u>而现在这一比例为80%</u>。</p><h4 id="总结："><a href="#总结：" class="headerlink" title="总结："></a>总结：</h4><p>减修饰——&gt;减插入语(两个破折号/逗号之间[判断是否为修饰])</p><p>抓主干(找谓语)——&gt; 减作修饰成分的介词短语to do/doing/done</p><p>快理解——&gt; 减从句(连接词始，一般第二个动词止)</p><h3 id="二、五大基本句型"><a href="#二、五大基本句型" class="headerlink" title="二、五大基本句型"></a>二、五大基本句型</h3><blockquote><p>句子主干：</p></blockquote><p>主谓宾</p><p>主系表</p><p>主谓                                      +             强调句</p><p>主谓宾宾</p><p>主谓宾补</p><blockquote><p>动词(谓语)</p></blockquote><p>动词的分类：</p><ol><li><p>实义动词</p><ul><li>及物动词 跟对象 eat/like/find（vt）</li><li>不及物动词 不需要对象 run/dance/swim （vi）</li></ul></li><li><p>系动词</p><p>能用be动词替换</p></li><li><p>助动词</p><p>时态[will]，否定[didn’t]，情态[can]</p></li></ol><hr><p>主谓宾     及物动词</p><p>主系表     系动词=be                三个句型 三种动词</p><p>主谓         不及物动词</p><p>主谓宾宾</p><p>主谓宾补</p><p>小技巧：如何判断宾宾和宾补？</p><p>在宾宾/宾补之间加一个(是/be)，如果说得通的是主谓宾补，说不通的是主谓宾宾</p><h4 id="强调句"><a href="#强调句" class="headerlink" title="强调句"></a>强调句</h4><p>例句：Xiao Cai plays basketball on the playground every day</p><p>强调主语：It is Xiao Cai who/that plays basketball on the playground every day.</p><p>强调宾语：It is basketball that Xiao Cai plays on the playground every day.</p><p>强调状语：It is on the playground that Xiao Cai plays basketball every day.</p><p>如何判断这个句子是不是强调句？</p><p>脱掉It is … that/who …,仍旧是一个完整的句子</p><h4 id="综合练习"><a href="#综合练习" class="headerlink" title="综合练习"></a>综合练习</h4><p>减修饰、找主干、判断句型</p><ol><li>The promotion of limited-edition “blind box” toys with the sale of KFC family buckets can easily induce impulse purchase of consummers and cause unnecessary food waste.</li></ol><hr><p>of limited-edition “blind box” toys</p><p>with the sale</p><p>of KFC family buckets </p><p>easily</p><p> of consummers</p><p>unnecessary        </p><hr><p>The promotion can induce impulse purchase and cause food waste.</p><p>主干翻译：促销会引发冲动消费并导致食物浪费。</p><p>主干基本句型：主谓宾</p><p>The promotion (of limited-edition “blind box” toys)(with the sale) (of KFC family buckets )can (easily) induce impulse purchase (of consummers) and cause (unnecessary) food waste.</p><p>长难句翻译：限量版盲盒玩具搭配肯德基全家桶套餐销售的促销方式，容易引发消费者的冲动消费，并导致不必要的食物浪费。</p><ol><li>The deal，which is expected to be valued at close to £2 billion，equivalent to around $2.3 billion,could be announced in the coming days.</li></ol><hr><p>which is expected to be valued at close to £2 billion</p><p>equivalent to around $2.3 billion</p><p>in the coming days.</p><hr><p>The deal could be announced.</p><p>主干翻译：这个交易可能会被宣布。</p><p>主干基本句型：主系表</p><p>The deal，（which is expected to be valued at close to £2 billion，）（equivalent to around $2.3 billion）,（could be announced）（ in the coming days.）</p><p>长难句翻译：</p><p>1.这笔预计估值接近20亿欧元、相当于23亿美元的交易，可能会在接下来几天公布。</p><p>2.这笔交易可能会在接下来几天宣布，交易预计估值接近20亿欧元、相当于23亿美元</p><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>主谓宾        及物动词</p><p>主谓            不及物动词            三个句型 三种动词</p><p>主系表            系动词=be</p><p>主谓宾补</p><p>主谓宾宾</p><p>强调句        It is … that/who …</p><h3 id="三、句子成分"><a href="#三、句子成分" class="headerlink" title="三、句子成分"></a>三、句子成分</h3><p>主 宾 表    —》 主角</p><p>定 状 同    —》修饰</p><h4 id="主语"><a href="#主语" class="headerlink" title="主语"></a>主语</h4><p>主语：动作发出者</p><p>由名词/代词/doing/to do/句子等充当</p><p>​        to do 某一次，未完成</p><p>do</p><p>​        doing 持续，习惯</p><h4 id="宾语"><a href="#宾语" class="headerlink" title="宾语"></a>宾语</h4><p>宾语：动作承受着</p><p>由名词/代词/doing/to do/句子等充当</p><p>位置：谓语动词之后/介词之后</p><h4 id="表语"><a href="#表语" class="headerlink" title="表语"></a>表语</h4><p>表语：修饰主语，用来说明主语的状态、特征</p><p>由名词/形容词/to do/doing/句子等充当</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;语法&quot;&gt;&lt;a href=&quot;#语法&quot; class=&quot;headerlink&quot; title=&quot;语法&quot;&gt;&lt;/a&gt;语法&lt;/h2&gt;&lt;h3 id=&quot;一、秒懂长难句&quot;&gt;&lt;a href=&quot;#一、秒懂长难句&quot; class=&quot;headerlink&quot; title=&quot;一、秒懂长难句&quot;&gt;&lt;/</summary>
      
    
    
    
    
  </entry>
  
</feed>
